// This file is generated by Nncase CPU module builder.
#include <array>
#include <cstdint>
#include <cstddef>
#include <cmath>
#include <cstring>
#include <span>
#include <utility>

// compiler support
#if defined(_MSC_VER)
#define __ISA_AVAILABLE_X86 0
#define __ISA_AVAILABLE_SSE2 1
#define __ISA_AVAILABLE_SSE42 2
#define __ISA_AVAILABLE_AVX 3
#define __ISA_AVAILABLE_ENFSTRG 4
#define __ISA_AVAILABLE_AVX2 5
#define __ISA_AVAILABLE_AVX512 6

extern "C" {
    int _fltused = 0;

    unsigned int __isa_available = __ISA_AVAILABLE_AVX;
    unsigned int __favor         = 0;
    
    void __chkstk() {
    }
}
#endif

extern "C" {
    struct nncase_runtime_cpu_mt_t {
        float (*acoshf)(float v);
    };

    nncase_runtime_cpu_mt_t *g_cpu_mt;
}

namespace nncase::runtime::cpu {
    template<class T, class Shape, class Strides>
    class tensor_view;

    // data types
    namespace detail
    {
        template<size_t...Dims>
        struct fixed_dims_base {
            static constexpr size_t rank() noexcept { return sizeof...(Dims); }

            static constexpr size_t at(size_t index) noexcept {
                return std::array<size_t, sizeof...(Dims)>{Dims...} [index] ;
            }
        };
    }

    template<size_t...Dims>
    struct fixed_shape : detail::fixed_dims_base<Dims...> {
        static constexpr size_t length() noexcept { return sizeof...(Dims) ? (Dims + ...) : 1; }
    };

    template<size_t...Strides>
    struct fixed_strides : detail::fixed_dims_base<Strides...> {
        template<size_t I>
        struct prepend {
            using type = fixed_strides<I, Strides...>;
        };
    };

    namespace detail {
        template<size_t I, size_t...Dims>
        struct default_strides_impl;

        template<size_t I>
        struct default_strides_impl<I> {
            inline static constexpr size_t value = 1;
            using strides_t = fixed_strides<value>;
        };

        template<size_t I, size_t Dim, size_t...Dims>
        struct default_strides_impl<I, Dim, Dims...> {
            using next_impl_t = default_strides_impl<I + 1, Dims...>;
            inline static constexpr size_t value = Dim * next_impl_t::value;
            using strides_t = typename next_impl_t::strides_t::template prepend<value>::type;
        };

        template<class Offset, class Strides, size_t...I>
        constexpr size_t linear_offset(std::index_sequence<I...>) noexcept {
            return ((Offset::at(I) * Strides::at(I)) + ...);
        }
    }

    template<class Shape>
    struct default_strides;

    template<size_t Dim, size_t ...Dims>
    struct default_strides<fixed_shape<Dim, Dims...>> {
        using type = typename detail::default_strides_impl<0, Dims...>::strides_t;
    };

    template<class Shape>
    using default_strides_t = typename default_strides<Shape>::type;

    template<class Offset, class Strides>
    constexpr size_t linear_offset() noexcept {
        return detail::linear_offset<Offset, Strides>(std::make_index_sequence<Offset::rank()>());
    }

    template<class T, class Shape, class Strides = default_strides_t<Shape>>
    class tensor {
    public:
        static constexpr auto shape() noexcept { return Shape{}; }
        static constexpr auto strides() noexcept { return Strides{}; }

        auto buffer() noexcept { return std::span(buffer_); }
        
        template<class Offset = fixed_shape<0>, class UShape = Shape>
        tensor_view<T, UShape, Strides> view() noexcept;

    private:
        T buffer_[shape().at(0) * strides().at(0)];
    };

    template<class T, class Shape, class Strides>
    class tensor_view {
    public:
        static constexpr auto shape() noexcept { return Shape{}; }
        static constexpr auto strides() noexcept { return Strides{}; }

        tensor_view(std::span<T, Shape::at(0) * Strides::at(0)> buffer) noexcept
            :buffer_(buffer) {}

        auto buffer() noexcept { return buffer_; }

        template<class Offset = fixed_shape<0>, class UShape = Shape>
        tensor_view<T, UShape, Strides> view() noexcept {
            return buffer_.template subspan<linear_offset<Offset, Strides>()>();
        }

    private:
        std::span<T, Shape::at(0) * Strides::at(0)> buffer_;
    };
    
    template<class T, class Shape, class Strides>
    template<class Offset, class UShape>
    tensor_view<T, UShape, Strides> tensor<T, Shape, Strides>::view() noexcept {
        return { buffer().template subspan<linear_offset<Offset, Strides>()>()};
    }

    // tensors
    template<class T, class Shape, class StridesA, class StridesB>
    void tensor_copy(tensor_view<T, Shape, StridesA> src, tensor_view<T, Shape, StridesB> dest) noexcept {
        auto src_buffer = src.buffer();
        std::copy(src_buffer.begin(), src_buffer.end(), dest.buffer().begin());
    }

    // math ops
    namespace mathops {
        struct abs {
            float operator()(float v) const noexcept { return fabs(v); }
        };

        struct acosh {
            float operator()(float v) const noexcept { return g_cpu_mt->acoshf(v); }
        };
    }

    template<class Op, class TVA, class TVB>
    void unary(TVA input, TVB output) {
        Op op;
        for (size_t i = 0; i < input.buffer().size(); i++) {
            output.buffer()[i] = op(input.buffer()[i]);
        }
    }
}
