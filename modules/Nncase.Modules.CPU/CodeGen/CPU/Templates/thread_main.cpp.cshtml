@using System.Linq
@using NetFabric.Hyperlinq
@using Nncase
@using Nncase.IR
@model Nncase.CodeGen.CPU.KernelMainModel
@{
  var inputCount = Model.PrimFunction.Parameters.Length;
}

#include <nncase/ntt/runtime.h>
#include "topo_aware_runtime.h"
#include <nncase/float8.h>
#include <nncase/half.h>
#include <nncase/bfloat16.h>
@foreach(var (s,i) in Model.Options.MemoryCapacities.Select((s,i) => (s,i)).SkipLast(1)){
@:uint8_t L@(i+1)Data[@(s)];
}
#include "../device.h"
#include "kernel.h"

//alignas(@(Model.Alignment)) static thread_local uint8_t local_data[@(Model.DataSize)];

extern "C" void thread_main(const nncase::ntt::runtime::thread_inout_desc *inouts, const std::byte *rdata, const std::byte *local_rdata) {
  /* prepare inputs */
  @{
    var names = new List<string>();
    var dynamicVars = IRHelpers.GetDynamicDimVars();
  }
  @foreach(var (input,i) in Model.PrimFunction.Parameters.ToArray().Select((input,i)=>(input,i)))
  {
    if (dynamicVars.Contains(input))
    {
      names.Add(input.Name);
  @:int64_t @Html.Raw(input.Name) = *(int64_t *)inouts[@i].data;
    }
    else
    {
      names.Add(input.Name);
      var shape = input.CheckedShape;
      var rank = shape.Rank;
      var sizeStr = $"inouts[{i}].size / {input.CheckedDataType.SizeInBytes}";
      var elemType = input.CheckedDataType.ToC();
      var dimType = shape.IsFixed ? $"fixed_shape<{string.Join(", ", Enumerable.Range(0, rank).Select(d => shape[d].FixedValue))}>" : $"ranked_shape<{rank}>";
      var stridesType = $"ranked_strides<{rank}>";
      var dimStr = shape.IsFixed ? ", {}" : $", make_ranked_shape({string.Join(", ", Enumerable.Range(0, rank).Select(d => shape[d].IsFixed ? $"{shape[d].FixedValue}" : $"inouts[{i}].shape[{d}]"))})";
      var strideStr = $", make_ranked_strides({string.Join(", ", Enumerable.Range(0, rank).Select(d => $"inouts[{i}].strides[{d}]"))})";
  @:std::span<@Html.Raw(elemType)> p@(input.Name)((@Html.Raw(elemType) *)inouts[@i].data, @Html.Raw(sizeStr));
  @:tensor_view<@Html.Raw(elemType), @Html.Raw(dimType), @Html.Raw(stridesType)> @(input.Name)(p@(input.Name)@Html.Raw(dimStr)@Html.Raw(strideStr));
    }
  @:
  }
  /* prepare rdatas */
  @foreach(var (b,i) in Model.RDataBuffers.OfType<Nncase.TIR.Buffer>().Select((b,i)=>(Model.GetInfo(b),i)))
  {
    names.Add(b.Name);
    if (b.Distributed == null)
    {
  @:std::span<@Html.Raw(b.ElemType), @b.Size> p@(b.Name)((@Html.Raw(b.ElemType) *)(rdata + @b.Offset), @b.Size);
  @:tensor_view<@Html.Raw(b.ElemType), @Html.Raw(b.DimensionsStr), @Html.Raw(b.StridesStr)> @(b.Name)(p@(b.Name));
    }
    else
    {
  @:std::span<@Html.Raw(b.ElemType), @b.Size> p@(b.Name)((@Html.Raw(b.ElemType) *)(local_rdata + @b.Offset), @b.Size);
  @:sharded_tensor_view<@Html.Raw(b.ElemType), @Html.Raw(b.DimensionsStr), @Html.Raw(b.Distributed), @Html.Raw(b.StridesStr)> @(b.Name)(p@(b.Name));
    }
  @:
  }

  @if (Model.Options.Hierarchies.Length > 1) {
    throw new NotSupportedException($"not support multi form topology!");
  }
  
  auto local_data = (uint8_t *)nncase::ntt::runtime::thread_alloc(@Model.DataSize, @Model.Alignment);
  @(Model.PrimFunction.Name)(@(string.Join(", ", names)), local_data);
  nncase::ntt::runtime::thread_free(local_data);
}

#ifdef NNCASE_STANDALONE
int main([[maybe_unused]] int argc, [[maybe_unused]] char** argv) {
  std::byte *inputs[@inputCount];
  size_t align = @(Model.Alignment);
  @foreach(var (b,i) in Model.PrimFunction.Parameters.ToArray().OfType<Nncase.TIR.Buffer>().Select((b,i)=>(Model.GetInfo(b),i)))
  {
  @:inputs[@i] = (std::byte *)nncase::ntt::runtime::thread_alloc(sizeof(@Html.Raw(b.ElemType)) * @b.Size, align);
  }

  std::byte* rdata = (std::byte *)nncase::ntt::runtime::thread_alloc(@Model.RDataSize, align);
  std::byte* local_rdata = (std::byte *)nncase::ntt::runtime::thread_alloc(@Model.LocalRdataPoolSize, align);
  uint64_t local_rdata_header[@Model.Options.Hierarchies[0][^1] * 2];
  for (size_t tid = 0; tid < tdim(); tid++) {
    local_rdata_header[tid * 2] = tid * ( @Model.LocalRdataPoolSize / tdim());
  }

#ifdef __APPLE__
  pthread_key_t cpu_thread_context_key_ = {};
  pthread_key_create(&cpu_thread_context_key_, [](void *ptr) { delete (nncase::ntt::runtime::cpu_thread_context_t *)ptr; });
#endif

  std::vector<std::thread> blocks;
  for (size_t cid = 0; cid < cdim(); cid++) {
    for (size_t bid = 0; bid < bdim(); bid++) {
      blocks.emplace_back([cid, bid, inputs, rdata, local_rdata_header, local_rdata
#ifdef __APPLE__
      , &cpu_thread_context_key_
#endif
      ] {
        nncase::ntt::runtime::cpu_block_entry_params_t block_entry_params{
            .tdim = tdim(),
            .bdim = bdim(),
            .cdim = cdim(),
            .bid = bid,
            .cid = cid,
            .cpu_id_offset = (cid * bdim() + bid) * tdim(),
            .inouts = inputs,
            .rdata = rdata,
            .local_rdata_header = local_rdata_header,
            .local_rdata = local_rdata,
#ifdef __APPLE__
            .cpu_thread_context_key = cpu_thread_context_key_,
#endif
        };

        block_entry(block_entry_params);
      });
    }
  }

  for (auto &block : blocks) {
    block.join();
  }
    
    
#ifdef __APPLE__
  pthread_key_delete(cpu_thread_context_key_);
#endif

  for (size_t i = 0; i < @inputCount; i++) {
    nncase::ntt::runtime::thread_free(inputs[i]);
  }
  nncase::ntt::runtime::thread_free(rdata);
  return 0;
}
#endif
