/* This file is generated by tools/stackvm_gen/IsaGen at 2022/5/27 下午3:58:52 +08:00.
 *
 * Copyright 2019-2021 Canaan Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#pragma once
#include <nncase/kernels/kernel_context.h>
#include <nncase/runtime/datatypes.h>
#include <nncase/runtime/error.h>
#include <nncase/runtime/result.h>
#include <nncase/runtime/stackvm/opcode.h>
#include <nncase/tensor.h>
#include <nncase/value.h>

BEGIN_NS_NNCASE_KERNELS_MODULE(stackvm)

NNCASE_API result<tensor> batch_normalization(tensor input, tensor scale, tensor bias, tensor input_mean, tensor input_var, tensor epsilon, tensor momentum, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> batch_to_space(tensor input, tensor block_shape, tensor crops, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> binary(runtime::stackvm::binary_op_t binary_op, tensor lhs, tensor rhs, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> broadcast(tensor input, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> cast(typecode_t new_type, tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> celu(tensor input, tensor alpha, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> clamp(tensor input, tensor min, tensor max, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> compare(runtime::stackvm::compare_op_t compare_op, tensor lhs, tensor rhs, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> concat(tensor input, tensor axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> conv2d(runtime::stackvm::pad_mode_t pad_mode, tensor input, tensor weights, tensor bias, tensor stride, tensor padding, tensor dilation, tensor groups, tensor fused_clamp, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> conv2d_transpose(runtime::stackvm::pad_mode_t pad_mode, tensor input, tensor weights, tensor bias, tensor output_shape, tensor stride, tensor padding, tensor output_padding, tensor dilation, tensor groups, tensor fused_clamp, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> cum_sum(tensor input, tensor axis, tensor exclusive, tensor reverse, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> dequantize(typecode_t target_type, tensor input, tensor dequant_param, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> elu(tensor input, tensor alpha, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> expand(tensor input, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> flatten(tensor input, tensor axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> gather(tensor input, tensor axis, tensor index, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> gather_nd(tensor input, tensor batch_dims, tensor index, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> get_item(tensor input, tensor index, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> hard_sigmoid(tensor input, tensor alpha, tensor beta, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> hard_swish(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> hardmax(tensor input, tensor axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> instance_normalization(tensor input, tensor scale, tensor bias, tensor epsilon, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> l2_normalization(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> leaky_relu(tensor input, tensor alpha, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> log_softmax(tensor input, tensor axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> lp_normalization(tensor input, tensor axis, tensor p, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> lrn(tensor input, tensor alpha, tensor beta, tensor bias, tensor size, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> lstm(runtime::stackvm::lstmdirection_t direction, runtime::stackvm::lstmlayout_t layout, std::vector<std::string> activations, tensor x, tensor w, tensor r, tensor b, tensor sequence_lens, tensor initial_h, tensor initial_c, tensor p, tensor activation_alpha, tensor activation_beta, tensor clip, tensor hidden_size, tensor input_forget, tensor output_size, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> mat_mul(tensor lhs, tensor rhs, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> normal(typecode_t type, tensor mean, tensor scale, tensor seed, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> normal_like(typecode_t type, tensor input, tensor mean, tensor scale, tensor seed, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> one_hot(runtime::stackvm::one_hot_mode_t one_hot_mode, tensor indices, tensor depth, tensor values, tensor axis, tensor on_value, tensor off_value, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> pad(runtime::stackvm::pad_mode_t pad_mode, tensor input, tensor pads, tensor value, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> prelu(tensor input, tensor slope, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> prod(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> quant_param_of(runtime::stackvm::quant_mode_t quant_mode, tensor range, tensor bits, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> quantize(typecode_t target_type, tensor input, tensor quant_param, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> range(tensor begin, tensor end, tensor step, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> range_of(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> reduce(runtime::stackvm::reduce_op_t reduce_op, tensor input, tensor axis, tensor init_value, tensor keep_dims, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> reduce_arg(runtime::stackvm::reduce_arg_op_t reduce_arg_op, tensor input, tensor axis, tensor keep_dims, tensor select_last_index, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> reduce_window2d(runtime::stackvm::reduce_op_t reduce_op, tensor input, tensor init_value, tensor filter, tensor stride, tensor padding, tensor dilation, tensor ceil_mode, tensor count_include_pad, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> relu(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> relu6(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> require(std::string message, tensor predicate, tensor value, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> reshape(tensor input, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> resize_image(runtime::stackvm::image_resize_mode_t resize_mode, runtime::stackvm::image_resize_transformation_mode_t transformation_mode, runtime::stackvm::image_resize_nearest_mode_t nearest_mode, bool is_tfresize, tensor input, tensor roi, tensor new_size, tensor cubic_coeff_a, tensor exclude_outside, tensor extrapolation_value, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> reverse_sequence(tensor input, tensor seq_lens, tensor batch_axis, tensor time_axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> select(tensor predicate, tensor true_value, tensor false_value, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> selu(tensor input, tensor alpha, tensor gamma, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> shape_of(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> sigmoid(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> size_of(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> slice(tensor input, tensor begins, tensor ends, tensor axes, tensor strides, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> softmax(tensor input, tensor axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> softplus(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> softsign(tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> space_to_batch(tensor input, tensor block_shape, tensor paddings, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> split(tensor input, tensor axis, tensor sections, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> squeeze(tensor input, tensor dim, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> stack(tensor inputs, tensor axis, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> tile(tensor input, tensor repeats, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> transpose(tensor input, tensor perm, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> unary(runtime::stackvm::unary_op_t unary_op, tensor input, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> uniform(typecode_t type, tensor high, tensor low, tensor seed, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> uniform_like(typecode_t type, tensor input, tensor high, tensor low, tensor seed, tensor shape, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> unsqueeze(tensor input, tensor dim, tensor output = nullptr, kernel_context &context = default_kernel_context());

NNCASE_API result<tensor> where(tensor cond, tensor x, tensor y, tensor output = nullptr, kernel_context &context = default_kernel_context());

END_NS_NNCASE_KERNELS_MODULE
