/* This file is generated by tools/stackvm_gen/IsaGen at 2022/5/14 下午6:47:34
 * +08:00.
 *
 * Copyright 2019-2021 Canaan Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
#pragma once
#include <nncase/kernels/kernel_context.h>
#include <nncase/runtime/datatypes.h>
#include <nncase/runtime/error.h>
#include <nncase/runtime/result.h>
#include <nncase/runtime/stackvm/opcode.h>
#include <nncase/tensor.h>
#include <nncase/value.h>

BEGIN_NS_NNCASE_KERNELS_MODULE(stackvm)
namespace optimized {

NNCASE_API result<void>
conv2d(const float *input, const float *weights, const float *bias,
       float *output, gsl::span<const size_t> in_shape, gsl::span<const size_t> in_strides,
       gsl::span<const size_t> w_shape, NNCASE_UNUSED gsl::span<const size_t> w_strides,
       NNCASE_UNUSED gsl::span<const size_t> bias_strides,
       NNCASE_UNUSED gsl::span<const size_t> out_strides, const padding &padding_h,
       const padding &padding_w, int32_t groups, int32_t stride_h,
       int32_t stride_w, int32_t dilation_h, int32_t dilation_w,
       value_range<float> fused_activation,
       NNCASE_UNUSED kernels::kernel_context &context) noexcept;

NNCASE_API result<void>
gather_nd(datatype_t type, const gsl::byte *input, gsl::byte *output,
          gsl::span<const size_t> in_shape, gsl::span<const size_t> out_shape,
          gsl::span<const size_t> in_strides, gsl::span<const size_t> out_strides,
          datatype_t indices_type, const gsl::byte *indices,
          gsl::span<const size_t> indices_shape, size_t batch_dims,
          kernel_context &context) noexcept;

NNCASE_API result<void> concat(datatype_t type,
                               gsl::span<const gsl::byte *const> inputs,
                               gsl::byte *output, gsl::span<const size_t> out_shape,
                               gsl::span<const dims_t> in_strides,
                               gsl::span<const size_t> out_strides, size_t axis,
                               gsl::span<const size_t> concat_dims,
                               kernel_context &context) noexcept;

NNCASE_API result<void>
dequantize(datatype_t in_type, datatype_t out_type, const gsl::byte *input,
           gsl::byte *output, gsl::span<const size_t> in_shape,
           NNCASE_UNUSED gsl::span<const size_t> in_strides,
           NNCASE_UNUSED gsl::span<const size_t> out_strides, float scale, float bias,
           NNCASE_UNUSED kernel_context &context) noexcept;

NNCASE_API result<void>
gather(datatype_t type, const gsl::byte *input, gsl::byte *output,
       gsl::span<const size_t> in_shape, gsl::span<const size_t> out_shape,
       gsl::span<const size_t> in_strides, gsl::span<const size_t> out_strides,
       datatype_t indices_type, const gsl::byte *indices,
       gsl::span<const size_t> indices_shape, size_t axis,
       kernel_context &context) noexcept;

NNCASE_API result<void> layer_norm(const float *input, float *output,
                                   const float *scale, const float *bias,
                                   gsl::span<const size_t> in_shape, int32_t axis,
                                   float epsilon);

NNCASE_API result<void>
one_hot(datatype_t type, datatype_t indices_type, const gsl::byte *indices,
        gsl::byte *output, gsl::span<const size_t> indices_shape, gsl::span<const size_t> out_shape,
        gsl::span<const size_t> out_strides, size_t depth, gsl::byte *values, size_t axis,
        runtime::stackvm::one_hot_mode_t mode,
        kernel_context &context) noexcept;

NNCASE_API result<void>
quantize(datatype_t in_type, datatype_t out_type, const gsl::byte *input,
         gsl::byte *output, gsl::span<const size_t> in_shape,
         NNCASE_UNUSED gsl::span<const size_t> in_strides,
         NNCASE_UNUSED gsl::span<const size_t> out_strides, float scale, float bias,
         NNCASE_UNUSED kernel_context &context) noexcept;

NNCASE_API result<void>
resize_bilinear(typecode_t type, const gsl::byte *input, gsl::byte *output,
                gsl::span<const size_t> in_shape, gsl::span<const size_t> in_strides,
                gsl::span<const size_t> out_strides, int32_t out_h, int32_t out_w,
                bool align_corners, bool half_pixel_centers,
                kernel_context &context) noexcept;

NNCASE_API result<void> resize_nearest_neighbor(
    typecode_t type, const gsl::byte *input, gsl::byte *output,
    gsl::span<const size_t> in_shape, gsl::span<const size_t> in_strides, gsl::span<const size_t> out_strides,
    int32_t out_h, int32_t out_w, bool align_corners, bool half_pixel_centers,
    kernel_context &context) noexcept;

NNCASE_API result<void>
slice(datatype_t type, const gsl::byte *input, gsl::byte *output,
      gsl::span<const size_t> in_shape, gsl::span<const size_t> in_strides,
      gsl::span<const size_t> out_strides, const axes_t &begins, const axes_t &ends,
      const axes_t &strides, NNCASE_UNUSED kernel_context &context) noexcept;

result<void> binary(typecode_t typecode, runtime::stackvm::binary_op_t op,
                    const gsl::byte *lhs, const gsl::byte *rhs,
                    gsl::byte *output, gsl::span<const size_t> lhs_shape,
                    gsl::span<const size_t> lhs_strides, gsl::span<const size_t> rhs_shape,
                    gsl::span<const size_t> rhs_strides, gsl::span<const size_t> out_shape,
                    gsl::span<const size_t> out_strides,
                    NNCASE_UNUSED kernel_context &context) noexcept;

NNCASE_API result<void>
unary(typecode_t dtype, runtime::stackvm::unary_op_t op, const gsl::byte *in,
      gsl::byte *out, gsl::span<const size_t> shape, gsl::span<const size_t> in_strides,
      gsl::span<const size_t> out_shape, gsl::span<const size_t> out_strides,
      kernel_context &context = default_kernel_context()) noexcept;

// template <typename T>
// NNCASE_API result<void> matmul(const T *input_a, const T *input_b, const T
// *bias, T *output,
//                               gsl::span<const size_t> in_a_shape, const dims_t
//                               &in_a_strides, gsl::span<const size_t> in_b_shape, const
//                               dims_t &in_b_strides, gsl::span<const size_t> out_shape,
//                               gsl::span<const size_t> out_strides, value_range<float>
//                               fused_activation) noexcept;

template <typename T>
NNCASE_API result<void>
softmax(const T *input, T *output, gsl::span<const size_t> in_shape,
        gsl::span<const size_t> in_strides, gsl::span<const size_t> out_strides, int32_t axis,
        float beta) noexcept;

template <typename T>
NNCASE_API result<void>
log_softmax(const T *input, T *output, gsl::span<const size_t> in_shape,
            gsl::span<const size_t> in_strides, gsl::span<const size_t> out_strides,
            int32_t axis) noexcept;

template <typename T>
NNCASE_API result<void>
sigmoid(const T *input, T *output, gsl::span<const size_t> in_shape,
        gsl::span<const size_t> input_strides, gsl::span<const size_t> out_shape,
        gsl::span<const size_t> out_strides,
        kernel_context &context = default_kernel_context()) noexcept;

NNCASE_API result<void>
where(datatype_t dt, const bool *cond, const gsl::byte *x, const gsl::byte *y,
      gsl::byte *output, gsl::span<const size_t> cond_shape, gsl::span<const size_t> x_shape,
      gsl::span<const size_t> y_shape, gsl::span<const size_t> out_shape,
      gsl::span<const size_t> cond_strides, gsl::span<const size_t> x_strides,
      gsl::span<const size_t> y_strides, gsl::span<const size_t> out_strides);

} // namespace optimized
END_NS_NNCASE_KERNELS_MODULE
