Subject: [PATCH] tflite
---
Index: src/Nncase.Evaluator/Tensors/Where.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Evaluator/Tensors/Where.cs b/src/Nncase.Evaluator/Tensors/Where.cs
--- a/src/Nncase.Evaluator/Tensors/Where.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Evaluator/Tensors/Where.cs	(date 1691378701985)
@@ -72,12 +72,19 @@
 
     public Expr Visit(IShapeEvaluateContext context, Where target)
     {
+        var x = context.GetArgumentShape(target, Where.X);
         if (target.IsTfWhere)
         {
+            var condValue = context.GetArgument(target, Where.Cond);
+            var condShape = context.GetArgumentShape(target, Where.Cond);
+            if (condValue.CheckedShape.Rank == 1)
+            {
+                return IR.F.Tensors.Stack(new IR.Tuple(new[] { condShape[0], x[0] }), 0);
+            }
+
             throw new NotImplementedException();
         }
 
-        var x = context.GetArgumentShape(target, Where.X);
         var y = context.GetArgumentShape(target, Where.Y);
         var cond = context.GetArgumentShape(target, Where.Cond);
         return ShapeExprUtility.BroadcastShape(x, y, cond);
Index: src/Nncase.Importer/TFLite/TFLiteImporter.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Importer/TFLite/TFLiteImporter.cs b/src/Nncase.Importer/TFLite/TFLiteImporter.cs
--- a/src/Nncase.Importer/TFLite/TFLiteImporter.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Importer/TFLite/TFLiteImporter.cs	(date 1691378701985)
@@ -66,17 +66,40 @@
     protected override (IEnumerable<Var> Inputs, Dictionary<Var, Expr[]> VarMap) CreateInputs()
     {
         var inputsCount = _subGraph.InputsLength;
-        var created_inputs = new Var[inputsCount];
+        var createdInputs = new Var[inputsCount];
+        var dynVarMap = Enumerable
+            .Range(0, inputsCount)
+            .SelectMany(i =>
+            {
+                var tensor = _subGraph.Tensors(_subGraph.Inputs(i))!.Value;
+                return Enumerable.Range(0, tensor.ShapeSignatureLength).Select(i => tensor.ShapeSignature(i)).Where(i => i < 0);
+            })
+            .ToHashSet()
+            .ToArray()
+            .Order()
+            .Select(i => new Var(i.ToString(), new TensorType(DataTypes.Int32, Shape.Scalar)))
+            .ToDictionary(v => v.Name, v => v);
+
+        if (dynVarMap.Count > 1)
+        {
+            throw new NotImplementedException();
+        }
+
+        var varMap = new Dictionary<Var, Expr[]>();
         for (int i = 0; i < inputsCount; i++)
         {
             var inputId = _subGraph.Inputs(i);
             var tensor = _subGraph.Tensors(inputId)!.Value;
             var input = new Var(tensor.Name, GetIRType(tensor));
-            created_inputs[i] = input;
+            var shape = input.CheckedShape.Select(x => x.IsFixed ? (Expr)x.FixedValue : dynVarMap.First().Value).ToArray();
+            varMap[input] = shape;
+            createdInputs[i] = input;
             _outputTensors.Add(inputId, input);
         }
 
-        return (created_inputs, new());
+        CompileSession.CompileOptions.ShapeBucketOptions =
+            CompileSession.CompileOptions.ShapeBucketOptions with { VarMap = varMap };
+        return (createdInputs, varMap);
     }
 
     protected override void ConvertOp()
@@ -133,7 +156,7 @@
         }
 
         return Enumerable.Range(0, tensor.ShapeLength).Select(i =>
-            tensor.Shape(i) == -1 ? Dimension.Unknown : tensor.Shape(i)).ToArray();
+            tensor.ShapeSignature(i) < 0 ? Dimension.Unknown : tensor.Shape(i)).ToArray();
     }
 
     private void Visit(in tflite.Operator op)
Index: src/Nncase.Importer/TFLite/Tile.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Importer/TFLite/Tile.cs b/src/Nncase.Importer/TFLite/Tile.cs
--- a/src/Nncase.Importer/TFLite/Tile.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Importer/TFLite/Tile.cs	(date 1691378701988)
@@ -12,7 +12,7 @@
         private Expr VisitTile(in tflite.Operator op)
         {
             var (input, multiples) = GetInputExprs(op, 0, 1);
-            return Tile(input, multiples);
+            return Tile(input, Cast(multiples, DataTypes.Int64));
         }
     }
 }
Index: src/Native/src/kernels/stackvm/optimized/riscv64/unary.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Native/src/kernels/stackvm/optimized/riscv64/unary.cpp b/src/Native/src/kernels/stackvm/optimized/riscv64/unary.cpp
--- a/src/Native/src/kernels/stackvm/optimized/riscv64/unary.cpp	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Native/src/kernels/stackvm/optimized/riscv64/unary.cpp	(date 1691378701985)
@@ -171,57 +171,59 @@
                               gsl::span<const size_t> out_shape,
                               gsl::span<const size_t> out_strides,
                               kernel_context &context) noexcept {
+    if(dtype == dt_float32) {
 #if __riscv_vector
-    auto *input = IN_CAST(float, in);
-    auto *output = OUT_CAST(float, out);
-    switch (op) {
-    case unary_op_t::abs: {
-        return optimized_unary_impl<unary_op_abs_rvv>(input, output, shape);
-    }
-    case unary_op_t::ceil: {
-        return optimized_unary_impl<unary_op_ceil_rvv>(input, output, shape);
-    }
-    case unary_op_t::cos: {
-        return optimized_unary_impl<unary_op_cos_rvv>(input, output, shape);
-    }
-    case unary_op_t::exp: {
-        return optimized_unary_impl<unary_op_exp_rvv>(input, output, shape);
-    }
-    case unary_op_t::floor: {
-        return optimized_unary_impl<unary_op_floor_rvv>(input, output, shape);
-    }
-    case unary_op_t::log: {
-        return optimized_unary_impl<unary_op_log_rvv>(input, output, shape);
-    }
-    case unary_op_t::neg: {
-        return optimized_unary_impl<unary_op_neg_rvv>(input, output, shape);
-    }
-    case unary_op_t::round: {
-        return optimized_unary_impl<unary_op_round_rvv>(input, output, shape);
-    }
-    case unary_op_t::rsqrt: {
-        return optimized_unary_impl<unary_op_rsqrt_rvv>(input, output, shape);
-    }
-    case unary_op_t::sign: {
-        return optimized_unary_impl<unary_op_sign_rvv>(input, output, shape);
-    }
-    case unary_op_t::sin: {
-        return optimized_unary_impl<unary_op_sin_rvv>(input, output, shape);
-    }
-    case unary_op_t::sqrt: {
-        return optimized_unary_impl<unary_op_sqrt_rvv>(input, output, shape);
-    }
-    case unary_op_t::square: {
-        return optimized_unary_impl<unary_op_square_rvv>(input, output, shape);
-    }
-    case unary_op_t::tanh: {
-        return optimized_unary_impl<unary_op_tanh_rvv>(input, output, shape);
-    }
-    default:;
-        //        std::cout << "Unsupported unary op: " + unary_op_to_string(op)
-        //        + " for optimizing, fallback to reference" << std::endl;
-    }
+        auto *input = IN_CAST(float, in);
+        auto *output = OUT_CAST(float, out);
+        switch (op) {
+        case unary_op_t::abs: {
+            return optimized_unary_impl<unary_op_abs_rvv>(input, output, shape);
+        }
+        case unary_op_t::ceil: {
+            return optimized_unary_impl<unary_op_ceil_rvv>(input, output, shape);
+        }
+        case unary_op_t::cos: {
+            return optimized_unary_impl<unary_op_cos_rvv>(input, output, shape);
+        }
+        case unary_op_t::exp: {
+            return optimized_unary_impl<unary_op_exp_rvv>(input, output, shape);
+        }
+        case unary_op_t::floor: {
+            return optimized_unary_impl<unary_op_floor_rvv>(input, output, shape);
+        }
+        case unary_op_t::log: {
+            return optimized_unary_impl<unary_op_log_rvv>(input, output, shape);
+        }
+        case unary_op_t::neg: {
+            return optimized_unary_impl<unary_op_neg_rvv>(input, output, shape);
+        }
+        case unary_op_t::round: {
+            return optimized_unary_impl<unary_op_round_rvv>(input, output, shape);
+        }
+        case unary_op_t::rsqrt: {
+            return optimized_unary_impl<unary_op_rsqrt_rvv>(input, output, shape);
+        }
+        case unary_op_t::sign: {
+            return optimized_unary_impl<unary_op_sign_rvv>(input, output, shape);
+        }
+        case unary_op_t::sin: {
+            return optimized_unary_impl<unary_op_sin_rvv>(input, output, shape);
+        }
+        case unary_op_t::sqrt: {
+            return optimized_unary_impl<unary_op_sqrt_rvv>(input, output, shape);
+        }
+        case unary_op_t::square: {
+            return optimized_unary_impl<unary_op_square_rvv>(input, output, shape);
+        }
+        case unary_op_t::tanh: {
+            return optimized_unary_impl<unary_op_tanh_rvv>(input, output, shape);
+        }
+        default:;
+            //        std::cout << "Unsupported unary op: " + unary_op_to_string(op)
+            //        + " for optimizing, fallback to reference" << std::endl;
+        }
 #endif
+    }
     return stackvm::reference::unary(dtype, op, in, out, shape, in_strides,
                                      out_shape, out_strides, context);
 }
\ No newline at end of file
Index: src/Nncase.Core/IR/Tensors/Functional.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Core/IR/Tensors/Functional.cs b/src/Nncase.Core/IR/Tensors/Functional.cs
--- a/src/Nncase.Core/IR/Tensors/Functional.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Core/IR/Tensors/Functional.cs	(date 1691378985971)
@@ -22,9 +22,41 @@
 {
     public static Call Transpose(Expr input, Expr perm) => new Call(new Transpose(), input, perm);
 
-    public static Expr NHWCToNCHW(Expr input) => Transpose(input, new[] { 0, 3, 1, 2 });
+    public static Expr NHWCToNCHW(Expr input)
+    {
+        int[] perm;
+        if (input.CheckedShape.Rank == 4)
+        {
+            perm = new[] { 0, 3, 1, 2 };
+        }
+        else if (input.CheckedShape.Rank == 3)
+        {
+            perm = new[] { 2, 0, 1 };
+        }
+        else
+        {
+            throw new InvalidOperationException();
+        }
+        return Transpose(input, perm);
+    }
 
-    public static Expr NCHWToNHWC(Expr input) => Transpose(input, new[] { 0, 2, 3, 1 });
+    public static Expr NCHWToNHWC(Expr input)
+    {
+        int[] perm;
+        if (input.CheckedShape.Rank == 4)
+        {
+            perm = new[] { 0, 2, 3, 1 };
+        }
+        else if (input.CheckedShape.Rank == 3)
+        {
+            perm = new[] { 1, 2, 0 };
+        }
+        else
+        {
+            throw new InvalidOperationException();
+        }
+        return Transpose(input, perm);
+    }
 
     public static Expr NHWCToWNCH(Expr input) => Transpose(input, new[] { 2, 0, 3, 1 });
 
Index: src/Nncase.Evaluator/NN/BatchToSpace.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Evaluator/NN/BatchToSpace.cs b/src/Nncase.Evaluator/NN/BatchToSpace.cs
--- a/src/Nncase.Evaluator/NN/BatchToSpace.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Evaluator/NN/BatchToSpace.cs	(date 1691378701985)
@@ -4,11 +4,13 @@
 using System;
 using System.Collections.Generic;
 using System.Diagnostics;
+using System.Drawing;
 using System.Linq;
 using Nncase.CostModel;
 using Nncase.IR;
 using Nncase.IR.NN;
 using Nncase.IR.Tensors;
+using Nncase.Utilities;
 using OrtKISharp;
 using static Nncase.IR.F.Tensors;
 
@@ -17,15 +19,15 @@
 /// <summary>
 /// Evaluator for <see cref="BatchToSpace"/>.
 /// </summary>
-public class BatchToSpaceEvaluator : IEvaluator<BatchToSpace>, ITypeInferencer<BatchToSpace>, ICostEvaluator<BatchToSpace>, IMetricEvaluator<BatchToSpace>
+public class BatchToSpaceEvaluator : IEvaluator<BatchToSpace>, ITypeInferencer<BatchToSpace>, ICostEvaluator<BatchToSpace>, IMetricEvaluator<BatchToSpace>, IShapeEvaluator<BatchToSpace>
 {
     /// <inheritdoc/>
     public IValue Visit(IEvaluateContext context, BatchToSpace s)
     {
-        var input = context.GetOrtArgumentValue(s, BatchToSpace.Input);
+        var input = context.GetArgumentValue(s, BatchToSpace.Input);
 
         // to nhwc
-        var input0 = OrtKI.Transpose(input, new long[] { 0, 2, 3, 1 });
+        var input0 = NCHWToNHWC(input.AsTensor()).Evaluate().AsTensor().ToOrtTensor();
         var blockShape = context.GetArgumentValueAsArray<int>(s, BatchToSpace.BlockShape);
         var crop = context.GetOrtArgumentValue(s, BatchToSpace.Crops).Cast(OrtDataType.Int32);
 
@@ -65,8 +67,8 @@
         var result = OrtKI.Slice(x3, cropStart, endRange, axesConst, strideConst);
 
         // to nchw
-        var transposeResult = OrtKI.Transpose(result, new long[] { 0, 3, 1, 2 });
-        return transposeResult.ToValue();
+        var transposeResult = NHWCToNCHW(result.ToTensor()).Evaluate();
+        return transposeResult;
     }
 
     /// <inheritdoc/>
@@ -135,8 +137,9 @@
 
     private IRType Visit(ITypeInferenceContext context, BatchToSpace target, TensorType input, TensorType blockShape, TensorType crops)
     {
-        // todo:
-        var inShape = TypeInference.ApplyPerm(input.Shape, new[] { 0, 2, 3, 1 });
+        var inShape = input.Shape.Rank == 4
+            ? TypeInference.ApplyPerm(input.Shape, new[] { 0, 2, 3, 1 })
+            : TypeInference.ApplyPerm(input.Shape, new[] { 1, 2, 0 });
         var batch = inShape[0];
         if (context.GetArgument(target, BatchToSpace.BlockShape) is TensorConst blockShapeValue &&
             context.GetArgument(target, BatchToSpace.Crops) is TensorConst cropsValue)
@@ -158,12 +161,61 @@
             var remainSize = inShape.Rank - 1 - m;
             var remainShape = remainSize > 0 ? inShape.Skip(1 + m) : Array.Empty<Dimension>();
             var outShapeList = new[] { d0 }.Concat(cropSection).Concat(remainShape).ToArray();
-            var outShape = TypeInference.ApplyPerm(outShapeList, new[] { 0, 3, 1, 2 });
+            var outShape =
+                outShapeList.Length == 4
+                ? TypeInference.ApplyPerm(outShapeList, new[] { 0, 3, 1, 2 })
+                : TypeInference.ApplyPerm(outShapeList, new[] { 2, 0, 1 });
             return input with { Shape = outShape };
         }
         else
         {
-            return new InvalidType("BatchToSpace can't infer shape with dynamic crops");
+            return new TensorType(input.DType, Enumerable.Repeat(Dimension.Unknown, input.Shape.Count).ToArray());
+        }
+    }
+
+    public Expr Visit(IShapeEvaluateContext context, BatchToSpace target)
+    {
+        var inShape = context.GetArgumentShape(target, BatchToSpace.Input);
+        var input = context.GetArgument(target, BatchToSpace.Input);
+        if (input.CheckedShape.Rank == 4)
+        {
+            inShape = Stack(new IR.Tuple(inShape[0], inShape[2], inShape[3], inShape[1]), 0);
+        }
+
+        if(input.CheckedShape.Rank == 3)
+        {
+            inShape = Stack(new IR.Tuple(inShape[1], inShape[2], inShape[0]), 0);
+        }
+
+        var blockShape = context.GetArgument(target, BatchToSpace.BlockShape);
+        if (!blockShape.CheckedShape.IsFixed)
+        {
+            throw new NotImplementedException();
         }
+        var crops = context.GetArgument(target, BatchToSpace.Crops);
+        var blockSize = Prod(blockShape);
+        var batch = inShape[0];
+        var d0 = batch / blockSize;
+        var m = blockShape.CheckedShape[0].FixedValue;
+        var cropSection = Enumerable.Range(0, m).Select(
+            i => (inShape[i + 1] * blockShape[0]) - crops[i, 0] - crops[i, 1]).ToArray();
+
+        var inRank = Cast(ShapeOf(inShape)[0], DataTypes.Int32);
+        var remainSize = inRank - 1 - m;
+        var remainShape = new If(remainSize > 0, ShapeExprUtility.Slice(inShape, 1 + m, int.MaxValue), Array.Empty<int>());
+
+        var outShapeList = Concat(new IR.Tuple(Stack(new IR.Tuple(new[] { d0 }), 0), Stack(new IR.Tuple(cropSection), 0), remainShape), 0);
+
+        if (input.CheckedShape.Rank == 4)
+        {
+            return Stack(new IR.Tuple(outShapeList[0], outShapeList[3], outShapeList[1], outShapeList[2]), 0);
+        }
+
+        if(input.CheckedShape.Rank == 3)
+        {
+            return Stack(new IR.Tuple(outShapeList[2], outShapeList[0], outShapeList[1]), 0);
+        }
+
+        throw new NotImplementedException();
     }
 }
Index: src/Nncase.Tests/Evaluator/UnitTestShapeEvaluator.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Tests/Evaluator/UnitTestShapeEvaluator.cs b/src/Nncase.Tests/Evaluator/UnitTestShapeEvaluator.cs
--- a/src/Nncase.Tests/Evaluator/UnitTestShapeEvaluator.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Tests/Evaluator/UnitTestShapeEvaluator.cs	(date 1691378701988)
@@ -253,6 +253,46 @@
         TestOpShapeEval(input => Pad(input, new[,] { { 1, 2 }, { 1, 3 }, { 2, 4 }, { 6, 1 } }, PadMode.Constant, 0f));
     }
 
+    [Fact]
+    public void TestSpaceTobatch()
+    {
+        var dimVar = new Var(new TensorType(DataTypes.Int32, Shape.Scalar));
+        var input = new Var(new TensorType(DataTypes.Float32, new[] { 1, Dimension.Unknown, 192 }));
+        var paddings = Tensor.From(new[] { 0, 1 }, new[] { 1, 2 });
+        var expr = SpaceToBatch(input, new[] { 3 }, paddings);
+        var dict = new Dictionary<Var, Expr[]> { { input, new Expr[] { 1, dimVar, 192 } } };
+        var shape = expr.EvaluateShapeExpr(dict);
+        var varValues = new Dictionary<Var, IValue> { { dimVar, Value.FromTensor(8) } };
+        Dumpper.DumpIR(shape, "Shape");
+        var shapeValue = shape.Evaluate(varValues).AsTensor().ToArray<int>();
+        var evalShape = expr
+            .Evaluate(new Dictionary<Var, IValue> { { input, Value.FromTensor(Testing.Rand<float>(1, 8, 192)) } })
+            .AsTensor()
+            .Shape;
+        var fixedShape = evalShape.ToValueArray();
+        Assert.Equal(fixedShape, shapeValue);
+    }
+
+    [Fact]
+    public void TestBatchToSpace()
+    {
+        var dimVar = new Var(new TensorType(DataTypes.Int32, Shape.Scalar));
+        var input = new Var(new TensorType(DataTypes.Float32, new[] { Dimension.Unknown, 69, 192 }));
+        var paddings = Tensor.From(new[] { 0, 1 }, new[] { 1, 2 });
+        var expr = BatchToSpace(input, new[] { 3 }, paddings);
+        var dict = new Dictionary<Var, Expr[]> { { input, new Expr[] { dimVar, 69, 192 } } };
+        var shape = expr.EvaluateShapeExpr(dict);
+        var varValues = new Dictionary<Var, IValue> { { dimVar, Value.FromTensor(3) } };
+        Dumpper.DumpIR(shape, "Shape");
+        var shapeValue = shape.Evaluate(varValues).AsTensor().ToArray<int>();
+        var evalShape = expr
+            .Evaluate(new Dictionary<Var, IValue> { { input, Value.FromTensor(Testing.Rand<float>(3, 69, 192)) } })
+            .AsTensor()
+            .Shape;
+        var fixedShape = evalShape.ToValueArray();
+        Assert.Equal(fixedShape, shapeValue);
+    }
+
     [Fact]
     public void UnitTestSqueeze()
     {
Index: src/Nncase.Importer/TFLite/Conv2DTranspose.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Importer/TFLite/Conv2DTranspose.cs b/src/Nncase.Importer/TFLite/Conv2DTranspose.cs
--- a/src/Nncase.Importer/TFLite/Conv2DTranspose.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Importer/TFLite/Conv2DTranspose.cs	(date 1691378701985)
@@ -17,14 +17,19 @@
     {
         private Expr VisitConv2DTranspose(in tflite.Operator op)
         {
-            var outShape = ((TensorConst)GetInputExprs(op, 0)).Value.ToArray<int>();
+            var outShape = GetInputExprs(op, 0);
             var newOutShape = new[] { outShape[0], outShape[3], outShape[1], outShape[2] };
             var (input, weights) = GetInputExprs(op, 2, 1);
-            Expr bias = Enumerable.Repeat(0f, newOutShape[1]).ToArray();
+            Expr bias;
             if (op.InputsLength > 3)
             {
                 bias = GetInputExprs(op, 3);
             }
+            else
+            {
+                var oc = IR.F.Tensors.ShapeOf(weights)[0];
+                bias = IR.F.Tensors.Expand(new[] { 0f }, IR.F.Tensors.StackScalar(oc));
+            }
 
             var options = op.BuiltinOptionsAsTransposeConvOptions();
             var (_, _) = Util.GetHW(input);
@@ -45,7 +50,7 @@
                     F.Tensors.NHWCToNCHW(input),
                     F.Tensors.NHWCToNCHW(weights),
                     bias,
-                    newOutShape,
+                    IR.F.Tensors.Stack(new IR.Tuple(newOutShape), 0),
                     stride,
                     padding,
                     Tensor.From<long>(new long[] { 0, 0, 0, 0 }),
Index: src/Native/src/kernels/stackvm/reference/batch_to_space.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Native/src/kernels/stackvm/reference/batch_to_space.cpp b/src/Native/src/kernels/stackvm/reference/batch_to_space.cpp
--- a/src/Native/src/kernels/stackvm/reference/batch_to_space.cpp	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Native/src/kernels/stackvm/reference/batch_to_space.cpp	(date 1691378701985)
@@ -103,8 +103,13 @@
 dims_t infer_shape(gsl::span<const size_t> origin_in_shape,
                    gsl::span<const size_t> block_shape,
                    const paddings_t &crops) {
+    auto d4 = fixed_dims(0, 2, 3, 1);
+    auto d3 = fixed_dims(1, 2, 0);
+    auto inPerm = origin_in_shape.size() == 4
+                  ? gsl::span<const size_t>{d4.data(), d4.size()}
+                  : gsl::span<const size_t>{d3.data(), d3.size()};
     auto in_shape = kernels::stackvm::transpose_infer_shape(
-        origin_in_shape, fixed_dims(0, 2, 3, 1));
+            origin_in_shape, inPerm);
     auto batch = in_shape[0] / compute_size(block_shape);
     auto out_shape = dims_t{batch};
     auto m = block_shape.size();
@@ -117,8 +122,12 @@
         out_shape.insert(out_shape.end(), in_shape.end() - remain_size,
                          in_shape.end());
     }
-    return kernels::stackvm::transpose_infer_shape(out_shape,
-                                                   fixed_dims(0, 3, 1, 2));
+    auto outd4 = fixed_dims(0, 3, 1, 2);
+    auto outd3 = fixed_dims(2, 0, 1);
+    auto outPerm = origin_in_shape.size() == 4
+                   ? gsl::span<const size_t>{outd4.data(), outd4.size()}
+                   : gsl::span<const size_t>{outd3.data(), outd3.size()};
+    return kernels::stackvm::transpose_infer_shape(out_shape, outPerm);
 }
 
 result<value_t> kernels::stackvm::batch_to_space(value_t input,
Index: src/Native/src/kernels/stackvm/reference/space_to_batch.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Native/src/kernels/stackvm/reference/space_to_batch.cpp b/src/Native/src/kernels/stackvm/reference/space_to_batch.cpp
--- a/src/Native/src/kernels/stackvm/reference/space_to_batch.cpp	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Native/src/kernels/stackvm/reference/space_to_batch.cpp	(date 1691378701985)
@@ -25,37 +25,19 @@
 using namespace nncase::kernels::stackvm;
 
 namespace {
-
-std::vector<size_t> concat(const std::vector<std::vector<size_t>> &containers) {
-    std::vector<size_t> result;
-    for (size_t i = 0; i < containers.size(); ++i) {
-        result.insert(result.end(), containers[i].begin(), containers[i].end());
-    }
-    return result;
-}
-
-template <typename T, typename Fn> std::vector<T> range_exec(int end, Fn &&f) {
-    std::vector<T> vec;
-    for (int i = 0; i < end; ++i) {
-        vec.push_back((T)f(i));
-    }
-    return vec;
-}
-
-template <typename Fn> std::vector<size_t> range_exec_flatten(int end, Fn &&f) {
-    auto result = range_exec<std::vector<size_t>>(end, f);
-    auto flatten = concat(result);
-    return flatten;
+inline dims_t get_transposed_shape(const dims_t &input_shape, const dims_t &perm)
+{
+    dims_t new_shape(input_shape.size());
+    for (size_t i = 0; i < new_shape.size(); i++)
+        new_shape[i] = input_shape[perm[i]];
+    return new_shape;
 }
 
 template <class T>
-result<void> space_to_batch_impl(
-    datatype_t dt, const T *input, T *output, gsl::span<const size_t> in_shape,
-    gsl::span<const size_t> block_shape, const paddings_t &paddings,
-    gsl::span<const size_t> in_strides,
-    [[maybe_unused]] gsl::span<const size_t> out_shape,
-    [[maybe_unused]] gsl::span<const size_t> out_strides,
-    NNCASE_UNUSED kernel_context &context) noexcept {
+result<void> space_to_batch_impl([[maybe_unused]] datatype_t dt, [[maybe_unused]] const T *input, [[maybe_unused]] T *output, [[maybe_unused]] const dims_t &in_shape, [[maybe_unused]] const dims_t &block_shape,
+                                 [[maybe_unused]] const paddings_t &paddings, [[maybe_unused]] const dims_t &in_strides, [[maybe_unused]] const dims_t &out_strides, [[maybe_unused]] kernel_context &context) noexcept
+{
+    auto in_shape_size = in_shape.size();
     auto spatial_size = block_shape.size();
     auto remain_shape_size = in_shape.size() - spatial_size - 1;
     auto new_paddings = paddings_t((1 + spatial_size + remain_shape_size));
@@ -63,63 +45,57 @@
         new_paddings[1 + i] = paddings[i];
     }
     auto pad_out_shape =
-        kernels::stackvm::pad_infer_shape(in_shape, new_paddings);
-    auto pad_output = std::make_unique<float[]>(compute_size(pad_out_shape));
+            kernels::stackvm::pad_infer_shape(in_shape, new_paddings);
+    auto size = compute_size(pad_out_shape);
+    auto pad_output = std::make_unique<float[]>(size);
     auto pad_out_strides = get_default_strides(pad_out_shape);
     int64_t pad_value = 0;
-    try_(kernels::stackvm::reference::pad(
-        dt, IN_BYTE_CAST(input), OUT_BYTE_CAST(pad_output.get()), in_shape,
-        in_strides, pad_out_strides, new_paddings,
-        nncase::runtime::stackvm::pad_mode_t::constant,
-        IN_BYTE_CAST(&pad_value)));
+
+    try_(kernels::stackvm::reference::pad(dt, reinterpret_cast<const gsl::byte *>(input),
+                        reinterpret_cast<gsl::byte *>(pad_output.get()), in_shape, in_strides,
+                        pad_out_strides, new_paddings,
+                        pad_mode_t::constant,
+                        IN_BYTE_CAST(&pad_value), context));
 
-    auto batch_shape1 = std::vector{pad_out_shape[0]};
-    auto spatial_shape1 = range_exec_flatten(spatial_size, [&](auto &&i) {
-        return std::vector{pad_out_shape[i + 1] / block_shape[i],
-                           block_shape[i]};
-    });
+    dims_t new_shape;
+    new_shape.reserve(in_shape_size + spatial_size);
+    new_shape.assign(pad_out_shape.begin(), pad_out_shape.begin() + in_shape_size - spatial_size);
 
-    auto remain_shape1 = range_exec<size_t>(remain_shape_size, [&](auto &&i) {
-        return pad_out_shape[1 + spatial_size + i];
-    });
+    dims_t perms(in_shape_size - spatial_size);
+    perms.reserve(in_shape_size + spatial_size);
+    std::iota(perms.begin(), perms.begin() + in_shape_size - spatial_size, 0);
 
-    //    auto remain_shape1 = concat(remain_shape1_tmp);
-    auto reshapeed_shape1 = concat(std::vector<std::vector<size_t>>{
-        batch_shape1, spatial_shape1, remain_shape1});
-    auto perm1 =
-        range_exec<size_t>(spatial_size, [&](auto &&i) { return i * 2 + 2; });
-    auto perm2 = std::vector<size_t>{0};
-    auto perm3 =
-        range_exec<size_t>(spatial_size, [&](auto &&i) { return i * 2 + 1; });
-    auto perm4 = range_exec<size_t>(
-        remain_shape_size, [&](auto &&i) { return i + spatial_size * 2 + 1; });
-    auto perms = std::vector<std::vector<size_t>>{perm1, perm2, perm3, perm4};
-    auto perm = concat(perms);
-    auto reshapeed_shape1_dims =
-        dims_t(reshapeed_shape1.begin(), reshapeed_shape1.end());
-    auto perm_dims = dims_t(perm.begin(), perm.end());
-    auto tr_out_shape = transpose_infer_shape(reshapeed_shape1_dims, perm_dims);
-    auto tr_out_stride = get_default_strides(tr_out_shape);
-    try_(kernels::stackvm::reference::transpose(
-        dt, IN_BYTE_CAST(pad_output.get()), OUT_BYTE_CAST(output),
-        reshapeed_shape1_dims, perm_dims,
-        get_default_strides(reshapeed_shape1_dims), tr_out_stride));
+    dims_t spatial_perms;
+    spatial_perms.reserve(spatial_size);
+
+    for (size_t i = 0; i < spatial_size; i++)
+    {
+        size_t idx = in_shape_size - spatial_size + i;
+        perms.push_back(new_shape.size());
+        new_shape.push_back(pad_out_shape[idx] / block_shape[i]);
+
+        spatial_perms.push_back(new_shape.size());
+        new_shape.push_back(block_shape[i]);
+    }
+
+    perms.insert(perms.begin(), spatial_perms.begin(), spatial_perms.end());
+
+    auto tp_shape = get_transposed_shape(new_shape, perms);
+    auto tp_stride = get_default_strides(tp_shape);
+    try_(kernels::stackvm::reference::transpose(dt, reinterpret_cast<const gsl::byte *>(pad_output.get()), reinterpret_cast<gsl::byte *>(output), new_shape, perms, get_default_strides(new_shape), tp_stride, context));
     return ok();
 }
-} // namespace
+}
 
-#define SPACE_TO_BATCH_IMPL(size, type)                                        \
-    case size:                                                                 \
-        return space_to_batch_impl(dt, reinterpret_cast<const type *>(input),  \
-                                   reinterpret_cast<type *>(output), in_shape, \
-                                   block_shape, paddings, in_strides,          \
-                                   out_shape, out_strides, context)
+#define SPACE_TO_BATCH_IMPL(size, type) \
+    case size:                          \
+        return space_to_batch_impl(dt, reinterpret_cast<const type *>(input), reinterpret_cast<type *>(output), in_shape, block_shape, paddings, in_strides, out_strides, context)
 
 result<void> nncase::kernels::stackvm::reference::space_to_batch(
     datatype_t dt, const gsl::byte *input, gsl::byte *output,
     gsl::span<const size_t> in_shape, gsl::span<const size_t> block_shape,
     const paddings_t &paddings, gsl::span<const size_t> in_strides,
-    gsl::span<const size_t> out_shape, gsl::span<const size_t> out_strides,
+    [[maybe_unused]] gsl::span<const size_t> out_shape, gsl::span<const size_t> out_strides,
     NNCASE_UNUSED kernel_context &context) {
     switch (runtime::get_bytes(dt)) {
         SPACE_TO_BATCH_IMPL(1, uint8_t);
Index: src/Nncase.Evaluator/NN/SpaceToBatch.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Evaluator/NN/SpaceToBatch.cs b/src/Nncase.Evaluator/NN/SpaceToBatch.cs
--- a/src/Nncase.Evaluator/NN/SpaceToBatch.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Evaluator/NN/SpaceToBatch.cs	(date 1691378701985)
@@ -9,7 +9,9 @@
 using Nncase.IR;
 using Nncase.IR.NN;
 using Nncase.IR.Tensors;
+using Nncase.Utilities;
 using OrtKISharp;
+using static Nncase.IR.F.Tensors;
 using Range = System.Range;
 
 namespace Nncase.Evaluator.NN;
@@ -17,7 +19,7 @@
 /// <summary>
 /// Evaluator for <see cref="SpaceToBatch"/>.
 /// </summary>
-public class SpaceToBatchEvaluator : IEvaluator<SpaceToBatch>, ITypeInferencer<SpaceToBatch>, ICostEvaluator<SpaceToBatch>, IMetricEvaluator<SpaceToBatch>
+public class SpaceToBatchEvaluator : IEvaluator<SpaceToBatch>, ITypeInferencer<SpaceToBatch>, ICostEvaluator<SpaceToBatch>, IMetricEvaluator<SpaceToBatch>, IShapeEvaluator<SpaceToBatch>
 {
     /// <inheritdoc/>
     public Cost Visit(ICostEvaluateContext context, SpaceToBatch target)
@@ -142,6 +144,43 @@
             return input with { Shape = new Shape(outshape) };
         }
 
-        return new InvalidType("Can't Infer Shape With Dynamic Input!");
+        return new TensorType(input.DType, Enumerable.Repeat(Dimension.Unknown, input.Shape.Count).ToArray());
     }
+
+    public Expr Visit(IShapeEvaluateContext context, SpaceToBatch target)
+    {
+        var inShape = context.GetArgumentShape(target, SpaceToBatch.Input);
+        var blockShape = context.GetArgument(target, SpaceToBatch.BlockShape);
+        var padding = context.GetArgument(target, SpaceToBatch.Paddings);
+        var input = context.GetArgument(target, SpaceToBatch.Input);
+        if (blockShape is TensorConst blockConst)
+        {
+            var blockShapeValue = blockConst.Value.ToArray<int>();
+            var m = blockShapeValue.Length;
+            var inRank = input.CheckedShape.Rank;
+            // todo: 这里没问题？？
+            var paddedShape = new[]{inShape[0]}
+                .Concat(Enumerable.Range(0, inRank)
+                .Select(i =>
+                {
+                    return inShape[i + 1] + padding[2 * i, 0] + padding[2 * i, 1];
+                }))
+                .ToArray();
+            var outFirst = new[] { paddedShape[0] * IR.F.Tensors.Prod(blockShapeValue) };
+
+            // var inRank = Cast(ShapeOf(inShape)[0], DataTypes.Int32);
+            var outMid = Enumerable.Range(0, m).Select(i =>
+            {
+                return paddedShape[i + 1] / blockShapeValue[i];
+            }).ToArray();
+
+            var remainSize = inRank - 1 - m;
+            var remainShape = new If(remainSize > 0, ShapeExprUtility.Slice(inShape, 1 + m, int.MaxValue), Array.Empty<int>());
+            var outLast = remainShape;
+            var outShape = Concat(new IR.Tuple(Stack(new IR.Tuple(outFirst.Concat(outMid).ToArray()), 0), outLast), 0);
+            return outShape;
+        }
+
+        throw new NotImplementedException();
+;    }
 }
Index: src/Nncase.Passes/Rules/Neutral/CombineReshape.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Passes/Rules/Neutral/CombineReshape.cs b/src/Nncase.Passes/Rules/Neutral/CombineReshape.cs
--- a/src/Nncase.Passes/Rules/Neutral/CombineReshape.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Passes/Rules/Neutral/CombineReshape.cs	(date 1691378701988)
@@ -94,7 +94,8 @@
         {
             var significantInputShape = input.CheckedShape.ToValueArray().Where(x => x > 1).ToArray();
             var constSize = constInput.CheckedShape.ToValueArray()[0];
-            if (significantShape.SequenceEqual(significantInputShape) && oldShape[^1] == constSize)
+            // melgan
+            if (significantShape.SequenceEqual(significantInputShape) && oldShape.Length > 0 && oldShape[^1] == constSize)
             {
                 var broadcastIndex = Array.LastIndexOf(input.CheckedShape.ToValueArray(), constSize);
                 var newConstShape = Enumerable.Repeat(1, input.CheckedShape.Rank - 1 - broadcastIndex).ToList();
Index: src/Nncase.Passes/Rules/Neutral/CombineTranspose.cs
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Nncase.Passes/Rules/Neutral/CombineTranspose.cs b/src/Nncase.Passes/Rules/Neutral/CombineTranspose.cs
--- a/src/Nncase.Passes/Rules/Neutral/CombineTranspose.cs	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Nncase.Passes/Rules/Neutral/CombineTranspose.cs	(date 1691378701988)
@@ -81,7 +81,14 @@
 
     private Expr? GetReplace(Binary binary, Call binaryCall, Expr x, Expr y, Expr perm)
     {
-        var expandDim = perm.CheckedShape.Size - ((TensorConst)perm).Value.ToArray<int>()[perm.CheckedShape.Size - 1] - 1;
+        // melgan
+        var permV = ((TensorConst)perm).Value.ToArray<int>();
+        if (permV.Length == 0)
+        {
+            return null;
+        }
+
+        var expandDim = perm.CheckedShape.Size - permV[perm.CheckedShape.Size - 1] - 1;
 
         if (x is Const)
         {
Index: src/Native/src/kernels/stackvm/reference/pad.cpp
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/Native/src/kernels/stackvm/reference/pad.cpp b/src/Native/src/kernels/stackvm/reference/pad.cpp
--- a/src/Native/src/kernels/stackvm/reference/pad.cpp	(revision 93c2001296468287133300950a3c4b1f0559fd43)
+++ b/src/Native/src/kernels/stackvm/reference/pad.cpp	(date 1691378701985)
@@ -209,7 +209,7 @@
     auto unit = runtime::get_bytes(type);
     bool padding_before_is_zero =
         std::all_of(paddings.begin(), paddings.end(),
-                    [](const padding &p) { return p.before == 0; }) &&
+                    [](const padding &p) { return p.before == 0 && p.after >= 0; }) &&
         mode == pad_mode_t::constant && in_shape.size() >= 3;
 
     if (std::all_of(paddings.begin(), paddings.end(),
