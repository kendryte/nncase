from typing import Any, List, BinaryIO, Enum, ClassVar

import numpy


""" This block is generated by tools/stackvm_gen/CApiGen at 12/20/2024 5:27:07 PM +08:00. """


class MemoryAccessArchitecture(Enum):
    UMA = 0
    NUMA = 1


class NocArchitecture(Enum):
    Mesh = 0
    CrossBar = 1


class HierarchyKind(Enum):
    Parallel = 0
    SMT = 1


""" end the auto generated block by tools/stackvm_gen/CApiGen at 12/20/2024 5:27:07 PM +08:00. """

""" This block is generated by tools/stackvm_gen/CApiGen at 12/20/2024 5:27:07 PM +08:00. """


class CpuTargetOptions:
    def __init__(self) -> None: ...
    ModelName: str
    Packing: bool
    UnifiedMemoryArch: bool
    MemoryAccessArch: MemoryAccessArchitecture
    NocArch: NocArchitecture
    HierarchyKind: HierarchyKind
    Hierarchies: List[List[int]]
    HierarchyNames: str
    HierarchySizes: List[int]
    HierarchyLatencies: List[int]
    HierarchyBandWidths: List[int]
    MemoryCapacities: List[int]
    MemoryBandWidths: List[int]
    DistributedScheme: str
    CustomOpScheme: str


""" end the auto generated block by tools/stackvm_gen/CApiGen at 12/20/2024 5:27:07 PM +08:00. """


class CompileOptions:
    benchmark_only: bool
    dump_asm: bool
    dump_dir: Path
    dump_ir: bool
    swapRB: bool
    input_file: str
    input_range: List[float]
    input_shape: List[int]
    input_type: str
    is_fpga: bool
    mean: List[float]
    std: List[float]
    output_type: str
    preprocess: bool
    quant_type: str
    target: str
    w_quant_type: str
    use_mse_quant_w: bool
    input_layout: str
    output_layout: str
    letterbox_value: float
    def __init__(self) -> None: ...


class Compiler:
    def __init__(self, compile_options: CompileOptions) -> None: ...
    def compile(self) -> None: ...
    def create_evaluator(self, stage: int) -> GraphEvaluator: ...
    def gencode(self, stream: BinaryIO) -> None: ...
    def gencode_tobytes(self) -> bytes: ...
    def import_caffe(self, model: bytes, prototxt: bytes) -> None: ...
    def import_onnx(self, model: bytes, options: ImportOptions) -> None: ...
    def import_tflite(self, model: bytes, options: ImportOptions) -> None: ...
    def import_huggingface(self, model_path:str) -> None: ...
    def use_ptq(self, ptq_dataset_options: PTQTensorOptions) -> None: ...


class GraphEvaluator:
    def __init__(self) -> None: ...
    def get_input_tensor(self, index: int) -> Any: ...
    def get_output_tensor(self, index: int) -> Any: ...
    def run(self) -> None: ...
    @property
    def outputs_size(self) -> int: ...


class ImportOptions:
    huggingface_options: HuggingFaceOptions
    def __init__(self, import_options) -> None: ...


class MemoryRange:
    dtype: dtype
    location: int
    size: int
    start: int
    def __init__(self) -> None: ...


class PTQTensorOptions:
    calibrate_method: str
    input_mean: float
    input_std: float
    samples_count: int
    quant_type: str
    w_quant_type: str
    finetune_weights_method: str
    use_mix_quant: bool
    def __init__(self) -> None: ...
    def set_tensor_data(self, bytes: bytes) -> None: ...

class HuggingFaceAttentionBackend:
    __members__: ClassVar[dict] = ...  # read-only
    Default: ClassVar[HuggingFaceAttentionBackend] = ...
    PagedAttention: ClassVar[HuggingFaceAttentionBackend] = ...
    __entries: ClassVar[dict] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...
    def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...

class HuggingFaceOptions:
    attention_backend: HuggingFaceAttentionBackend
    output_attentions: bool
    output_hidden_states: bool
    use_cache: bool
    def __init__(self) -> None: ...

class Path:
    def __init__(self, path: str) -> None: ...


class RuntimeTensor:
    def __init__(self) -> None: ...
    def copy_to(self, to: RuntimeTensor) -> None: ...
    @staticmethod
    def from_numpy(self, arr: numpy.ndarray) -> Any: ...
    @staticmethod
    def from_object(arg0) -> RuntimeTensor: ...
    def to_numpy(self) -> numpy.ndarray: ...
    @property
    def dtype(self) -> dtype: ...
    @property
    def shape(self) -> List[int]: ...

class RTValue:
    def __init__(self, *args, **kwargs) -> None: ...
    @staticmethod
    def from_runtime_tensor(arg0: RuntimeTensor) -> RTValue: ...
    def to_runtime_tensor(self) -> RuntimeTensor: ...
    def to_runtime_tensors(self) -> list[RuntimeTensor]: ...

class Simulator:
    def __init__(self) -> None: ...
    def get_input_desc(self, index: int) -> MemoryRange: ...
    def get_input_tensor(self, index: int) -> RuntimeTensor: ...
    def get_output_desc(self, index: int) -> MemoryRange: ...
    def get_output_tensor(self, index: int) -> RuntimeTensor: ...
    def load_model(self, model: bytes) -> None: ...
    def run(self) -> None: ...
    def enable_profiling(self) -> None: ...
    def set_input_tensor(self, index: int, tensor: RuntimeTensor) -> None: ...
    def set_output_tensor(self, index: int, tensor: RuntimeTensor) -> None: ...
    @property
    def inputs_size(self) -> int: ...
    @property
    def outputs_size(self) -> int: ...


def test_target(target: str) -> bool: ...

class AttentionKVCache:
    def __init__(self, *args, **kwargs) -> None: ...

class AttentionConfig:
    head_dim: int
    num_kv_heads: int
    num_layers: int
    def __init__(self, num_layers: int, num_kv_heads: int, head_dim: int) -> None: ...

class PagedAttentionConfig(AttentionConfig):
    block_size: int
    def __init__(self, num_layers: int, num_kv_heads: int, head_dim: int, block_size: int) -> None: ...

class PagedAttentionScheduler:
    def __init__(self, max_model_len: int) -> None: ...
    def initialize(self, arg0: PagedAttentionConfig, num_blocks: int) -> None: ...
    def schedule(self, session_ids: RuntimeTensor, token_nums: RuntimeTensor) -> AttentionKVCache: ...
